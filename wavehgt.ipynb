{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import urllib\n",
    "from PIL import Image \n",
    "import time \n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from twilio.rest import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to send twillio text\n",
    "def send_text(msg):\n",
    "    client = Client(account, token)\n",
    "\n",
    "    message = client.messages.create(to=\"+\", from_=\"+12055836550\",\n",
    "                                 body=msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define website and station\n",
    "station_id = 44008 \n",
    "root_path = 'https://www.ndbc.noaa.gov'\n",
    "station_path = '/station_page.php?station='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean up df\n",
    "def clean_df(df):\n",
    "    df['TIME(EDT)'] = df['TIME(EDT)'].apply(lambda x: delete_code(x)) \n",
    "    df[['MM', 'DD']] = df[['MM', 'DD']].astype(str) #month and day to string\n",
    "    df['date_stamp'] = df.MM + ' ' + df.DD + ' ' + df['TIME(EDT)'] #create date stamp\n",
    "    df['time_stamp'] = df['date_stamp'].apply(lambda x: get_date(x)) #create time stamp \n",
    "    df.drop(['MM', 'DD', 'TIME(EDT)', 'date_stamp'], axis = 1, inplace = True) #drop \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get date as datetime object\n",
    "def get_date(x):\n",
    "    x = x.split()\n",
    "    mm = x[0]\n",
    "    dd = x[1]\n",
    "    time = str(x[2])\n",
    "    time = time.replace('\\xa0', '').encode('utf-8')\n",
    "    datetime_object = dt.datetime.strptime('{} {} {} {}' .format(x[0], x[1], 2020, time) , '%m %d %Y %I:%M%p')\n",
    "    return datetime_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eliminate unicode character\n",
    "def delete_code(x):\n",
    "    x = x.replace('\\\\xa0', '').encode('utf-8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get html\n",
    "def get_html(r_p, s_p, sta_id):\n",
    "    try:\n",
    "        filepath = r_p + s_p + '{}' .format(sta_id)\n",
    "        r = requests.get(url = filepath)\n",
    "        assert r.status_code == 200\n",
    "        r.raise_for_status()\n",
    "        html = r.content\n",
    "        return html\n",
    "    except:\n",
    "        raise ValueError('Could not retrieve HTML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get table and return dataframe\n",
    "def get_df(soup):\n",
    "    try:\n",
    "        table = soup.findAll(\"table\", class_=\"dataTable\")\n",
    "        df_1 = pd.read_html(str(table))[0]\n",
    "        df_2 = pd.read_html(str(table))[1]\n",
    "        return df_1, df_2\n",
    "    except:\n",
    "        raise ValueError('Could not get dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get src attribute\n",
    "def get_src_attr(soup, sta_id):\n",
    "    try:\n",
    "        img = soup.findAll('img', {'alt': 'Photos from Buoy Camera at station {}' .format(sta_id)})\n",
    "        src_attr = img[0]['src']\n",
    "        return src_attr\n",
    "    except:\n",
    "        raise ValueError('Could not retrieve src attribute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save image\n",
    "def save_img(img_path, src):\n",
    "    try:\n",
    "        raw_img = requests.get(url = img_path, stream = True)\n",
    "        raw_img.raise_for_status()\n",
    "        raw_img.raw.decode_content = True\n",
    "        timestamp = str(src).split('/')\n",
    "        with Image.open(raw_img.raw) as img:\n",
    "            img.save('Images/{}' .format(timestamp[-1]), 'JPEG')\n",
    "        raw_img.close() \n",
    "    except:\n",
    "        raise ValueError('Could not save image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gets data and/or image\n",
    "def retrieve_data(just_image, sta_id):\n",
    "    try:\n",
    "        html = get_html(root_path, station_path, sta_id)\n",
    "        soup = bs(html, 'html5lib')\n",
    "        if just_image:\n",
    "            src_attr = get_src_attr(soup, sta_id)   \n",
    "            img_path = root_path + src_attr \n",
    "            save_img(img_path, src_attr)\n",
    "        else:\n",
    "            df_1, df_2 = get_df(soup)\n",
    "            return df_1, df_2\n",
    "    except ValueError as err:\n",
    "        print(err.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seperates wind df\n",
    "def get_wind_df(df):\n",
    "    wind_df = clean_df(df)\n",
    "    wind_df = wind_df[['WDIR', 'WSPDkts', 'GSTkts', 'time_stamp']]\n",
    "    return wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seperates wave df\n",
    "def get_wave_df(df):\n",
    "    wave_df = clean_df(df)\n",
    "    wave_df = wave_df[['WVHTft', 'time_stamp']]\n",
    "    return wave_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merges wind, wave df\n",
    "def merge_dfs(df_1, df_2):\n",
    "    merged_df = df_1.merge(df_2, how='left', left_on='time_stamp', right_on='time_stamp')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(just_image):\n",
    "#get saved df\n",
    "    try:\n",
    "        old_df = pd.read_csv('dataset.csv')\n",
    "    except:\n",
    "        print('no dataset')\n",
    "    just_image = just_image\n",
    "    if just_image:\n",
    "        retrieve_data(just_image, 44008)\n",
    "    else:\n",
    "        df_1, df_2 = retrieve_data(just_image, 44008)\n",
    "        wind_df = get_wind_df(df_1)\n",
    "        wave_df = get_wave_df(df_2)\n",
    "        merged_df = wind_df.merge(wave_df, how='left', left_on='time_stamp', right_on='time_stamp')\n",
    "        merged_dfs = merged_df.append(old_df)\n",
    "        merged_dfs.drop_duplicates(inplace = True)\n",
    "        merged_dfs.to_csv('dataset.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8793\n",
      "('Could not get dataframe',)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c768dcb4a667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtime_stop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0meveryhour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-c768dcb4a667>\u001b[0m in \u001b[0;36meveryhour\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtime_stop\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtime_stop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-cf619312dea7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(just_image)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mretrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjust_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44008\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjust_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44008\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mwind_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wind_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mwave_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_wave_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "#runs every hour for duration, gets just df at 0 and 13\n",
    "def everyhour(): \n",
    "    time_stop = 0\n",
    "    while time_stop < 14:\n",
    "        if time_stop == 0 or time_stop == 13:\n",
    "            main(False)\n",
    "        else:\n",
    "            main(True)\n",
    "            time.sleep(3600)\n",
    "        time_stop += 1\n",
    "everyhour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#notes to self\n",
    "#Atlantic Daylight Time (ADT) is 3 hours behind Coordinated Universal Time (UTC).\n",
    "#This time zone is a Daylight Saving Time time zone and is used in: North America, Atlantic.\n",
    "#This time zone is often called ADT Time Zone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
