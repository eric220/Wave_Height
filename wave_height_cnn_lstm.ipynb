{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, LSTM, Flatten, TimeDistributed, Conv2D, Dropout, MaxPooling2D\n",
    "from keras import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "import keras.metrics as metrics\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image file names\n",
    "file_glob = glob.glob('Fixed_Images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv') \n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates found in WVHTft with nan\n",
    "df.drop_duplicates(['GSTkts', 'WDIR', 'WSPDkts', 'time_stamp'], keep='first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'time_stamp', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time_stamp = pd.to_datetime(df.time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8980 entries, 0 to 8979\n",
      "Data columns (total 5 columns):\n",
      "GSTkts        8980 non-null float64\n",
      "WDIR          8980 non-null object\n",
      "WSPDkts       8980 non-null float64\n",
      "WVHTft        1479 non-null float64\n",
      "time_stamp    8980 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(1)\n",
      "memory usage: 350.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in string name of image file, returns datetime object offset to match image time\n",
    "def get_time_stamp(name):\n",
    "    p = 0\n",
    "    img_date = name.split('_')[2:4]\n",
    "    img_edt = int(name.split('_')[-1:][0].split('.')[0])\n",
    "    img_edt = str(img_edt).zfill(4) \n",
    "    img_edt = list(img_edt)\n",
    "    img_edt[-2:] = ['4', '0'] #change all to 40min\n",
    "    img_edt = ''.join(img_edt)\n",
    "    img_edt = str(img_edt)\n",
    "    date = '{}-{}-{} {}' .format('2020', img_date[0], img_date[1], img_edt)\n",
    "    date = pd.to_datetime(date)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(mn, input_shape=(6, 224, 224, 3)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(MaxPooling2D()))\n",
    "model.add(TimeDistributed(Flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = 500\n",
    "\n",
    "#input string img_path, returns tensors list from 6 image slices, and int target\n",
    "def get_tensors_and_targets(file_names):\n",
    "    targets = []\n",
    "    tensor_stack = []\n",
    "    for f in file_names:\n",
    "        img_time = get_time_stamp(f)\n",
    "        target = df.query('time_stamp == @img_time')['WVHTft'] #gets wvht from match in database\n",
    "        if len(target) == 0:\n",
    "            print(img_paths)\n",
    "        else:\n",
    "            targets.append(target.values[0])\n",
    "        img = image.load_img(f, target_size=(260, 1344))\n",
    "        img_arr = np.array(img)\n",
    "        list_of_tensors = []\n",
    "        for i in range(0,6):\n",
    "            slice_show = i\n",
    "            slice_size = 1344/6\n",
    "            img_slice = img_arr[:224, slice_size * slice_show:slice_size * (slice_show + 1), :]\n",
    "            list_of_tensors.append(np.expand_dims(img_slice, axis=0).astype('float32')/255)\n",
    "        tensor_stack.append(np.vstack(list_of_tensors))\n",
    "    return tensor_stack, targets\n",
    "\n",
    "tensor_stack, targets = get_tensors_and_targets(file_glob[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for t in tensor_stack:\n",
    "    t = np.array(t).reshape(1, 6, 224, 224, 3)\n",
    "    preds = model.predict(t)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(predictions[:num_targets]).reshape(num_targets, 6, output_size)\n",
    "x_test = np.array(predictions[num_targets:]).reshape((len(targets) - num_targets), 6, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for inf or nan\n",
    "np.isfinite(x_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#fill nan targets with 3\n",
    "targets = pd.Series(targets)\n",
    "new_targets = targets.fillna(3)\n",
    "new_targets = np.array(new_targets)\n",
    "print(np.isfinite(new_targets).all())\n",
    "y_train = new_targets[:num_targets]\n",
    "y_test = new_targets[num_targets:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 5, min_lr = 0.0001, verbose = 1)\n",
    "early_stop = EarlyStopping(monitor = 'loss', patience = 10)\n",
    "checkpoint = ModelCheckpoint(filepath = 'base_model', monitor = 'loss', save_best_only = True, verbose = 1)\n",
    "callback_list = [checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_57 (LSTM)               (None, 6, 128)            590336    \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 722,049\n",
      "Trainable params: 722,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(128, return_sequences = True, input_shape = (6, output_size), dropout = .4))\n",
    "lstm.add(LSTM(128, dropout = .2))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss='mse', optimizer='adam', metrics = [metrics.mean_squared_error])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 375 samples, validate on 125 samples\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 10.4229 - mean_squared_error: 10.4229 - val_loss: 2.2507 - val_mean_squared_error: 2.2507\n",
      "\n",
      "Epoch 00001: loss improved from inf to 10.42290, saving model to base_model\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 6.2413 - mean_squared_error: 6.2413 - val_loss: 1.6199 - val_mean_squared_error: 1.6199\n",
      "\n",
      "Epoch 00002: loss improved from 10.42290 to 6.24127, saving model to base_model\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.6270 - mean_squared_error: 5.6270 - val_loss: 0.6986 - val_mean_squared_error: 0.6986\n",
      "\n",
      "Epoch 00003: loss improved from 6.24127 to 5.62697, saving model to base_model\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 4.5137 - mean_squared_error: 4.5137 - val_loss: 0.7954 - val_mean_squared_error: 0.7954\n",
      "\n",
      "Epoch 00004: loss improved from 5.62697 to 4.51370, saving model to base_model\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 3.2795 - mean_squared_error: 3.2795 - val_loss: 1.0614 - val_mean_squared_error: 1.0614\n",
      "\n",
      "Epoch 00005: loss improved from 4.51370 to 3.27947, saving model to base_model\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.4562 - mean_squared_error: 2.4562 - val_loss: 0.8059 - val_mean_squared_error: 0.8059\n",
      "\n",
      "Epoch 00006: loss improved from 3.27947 to 2.45622, saving model to base_model\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1245 - mean_squared_error: 2.1245 - val_loss: 1.2609 - val_mean_squared_error: 1.2609\n",
      "\n",
      "Epoch 00007: loss improved from 2.45622 to 2.12447, saving model to base_model\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8655 - mean_squared_error: 1.8655 - val_loss: 0.6653 - val_mean_squared_error: 0.6653\n",
      "\n",
      "Epoch 00008: loss improved from 2.12447 to 1.86553, saving model to base_model\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7750 - mean_squared_error: 1.7750 - val_loss: 0.9042 - val_mean_squared_error: 0.9042\n",
      "\n",
      "Epoch 00009: loss improved from 1.86553 to 1.77498, saving model to base_model\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0029 - mean_squared_error: 2.0029 - val_loss: 1.1808 - val_mean_squared_error: 1.1808\n",
      "\n",
      "Epoch 00010: loss did not improve from 1.77498\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1221 - mean_squared_error: 2.1221 - val_loss: 0.8900 - val_mean_squared_error: 0.8900\n",
      "\n",
      "Epoch 00011: loss did not improve from 1.77498\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6418 - mean_squared_error: 1.6418 - val_loss: 0.6474 - val_mean_squared_error: 0.6474\n",
      "\n",
      "Epoch 00012: loss improved from 1.77498 to 1.64177, saving model to base_model\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4494 - mean_squared_error: 1.4494 - val_loss: 0.9020 - val_mean_squared_error: 0.9020\n",
      "\n",
      "Epoch 00013: loss improved from 1.64177 to 1.44935, saving model to base_model\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3934 - mean_squared_error: 1.3934 - val_loss: 1.0104 - val_mean_squared_error: 1.0104\n",
      "\n",
      "Epoch 00014: loss improved from 1.44935 to 1.39338, saving model to base_model\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2376 - mean_squared_error: 1.2376 - val_loss: 0.6827 - val_mean_squared_error: 0.6827\n",
      "\n",
      "Epoch 00015: loss improved from 1.39338 to 1.23758, saving model to base_model\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2601 - mean_squared_error: 1.2601 - val_loss: 0.8111 - val_mean_squared_error: 0.8111\n",
      "\n",
      "Epoch 00016: loss did not improve from 1.23758\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2227 - mean_squared_error: 1.2227 - val_loss: 0.7991 - val_mean_squared_error: 0.7991\n",
      "\n",
      "Epoch 00017: loss improved from 1.23758 to 1.22274, saving model to base_model\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0104 - mean_squared_error: 1.0104 - val_loss: 0.7783 - val_mean_squared_error: 0.7783\n",
      "\n",
      "Epoch 00018: loss improved from 1.22274 to 1.01037, saving model to base_model\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9248 - mean_squared_error: 0.9248 - val_loss: 0.6922 - val_mean_squared_error: 0.6922\n",
      "\n",
      "Epoch 00019: loss improved from 1.01037 to 0.92480, saving model to base_model\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1793 - mean_squared_error: 1.1793 - val_loss: 0.6914 - val_mean_squared_error: 0.6914\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.92480\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0310 - mean_squared_error: 1.0310 - val_loss: 0.6575 - val_mean_squared_error: 0.6575\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.92480\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8262 - mean_squared_error: 0.8262 - val_loss: 0.6567 - val_mean_squared_error: 0.6567\n",
      "\n",
      "Epoch 00022: loss improved from 0.92480 to 0.82622, saving model to base_model\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9064 - mean_squared_error: 0.9064 - val_loss: 0.7566 - val_mean_squared_error: 0.7566\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.82622\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8363 - mean_squared_error: 0.8363 - val_loss: 0.7778 - val_mean_squared_error: 0.7778\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.82622\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8083 - mean_squared_error: 0.8083 - val_loss: 0.7180 - val_mean_squared_error: 0.7180\n",
      "\n",
      "Epoch 00025: loss improved from 0.82622 to 0.80827, saving model to base_model\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7330 - mean_squared_error: 0.7330 - val_loss: 0.9124 - val_mean_squared_error: 0.9124\n",
      "\n",
      "Epoch 00026: loss improved from 0.80827 to 0.73302, saving model to base_model\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8227 - mean_squared_error: 0.8227 - val_loss: 0.7169 - val_mean_squared_error: 0.7169\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.73302\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7336 - mean_squared_error: 0.7336 - val_loss: 0.7101 - val_mean_squared_error: 0.7101\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.73302\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8075 - mean_squared_error: 0.8075 - val_loss: 1.0633 - val_mean_squared_error: 1.0633\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.73302\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7530 - mean_squared_error: 0.7530 - val_loss: 1.0779 - val_mean_squared_error: 1.0779\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.73302\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6571 - mean_squared_error: 0.6571 - val_loss: 0.8134 - val_mean_squared_error: 0.8134\n",
      "\n",
      "Epoch 00031: loss improved from 0.73302 to 0.65709, saving model to base_model\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6322 - mean_squared_error: 0.6322 - val_loss: 1.0810 - val_mean_squared_error: 1.0810\n",
      "\n",
      "Epoch 00032: loss improved from 0.65709 to 0.63216, saving model to base_model\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7768 - mean_squared_error: 0.7768 - val_loss: 0.9429 - val_mean_squared_error: 0.9429\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.63216\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6678 - mean_squared_error: 0.6678 - val_loss: 0.7785 - val_mean_squared_error: 0.7785\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.63216\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5686 - mean_squared_error: 0.5686 - val_loss: 1.0159 - val_mean_squared_error: 1.0159\n",
      "\n",
      "Epoch 00035: loss improved from 0.63216 to 0.56863, saving model to base_model\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5990 - mean_squared_error: 0.5990 - val_loss: 0.8458 - val_mean_squared_error: 0.8458\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.56863\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6463 - mean_squared_error: 0.6463 - val_loss: 1.2912 - val_mean_squared_error: 1.2912\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.56863\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6631 - mean_squared_error: 0.6631 - val_loss: 1.1253 - val_mean_squared_error: 1.1253\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.56863\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5411 - mean_squared_error: 0.5411 - val_loss: 0.9805 - val_mean_squared_error: 0.9805\n",
      "\n",
      "Epoch 00039: loss improved from 0.56863 to 0.54110, saving model to base_model\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5717 - mean_squared_error: 0.5717 - val_loss: 1.1373 - val_mean_squared_error: 1.1373\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.54110\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4750 - mean_squared_error: 0.4750 - val_loss: 0.8998 - val_mean_squared_error: 0.8998\n",
      "\n",
      "Epoch 00041: loss improved from 0.54110 to 0.47500, saving model to base_model\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4532 - mean_squared_error: 0.4532 - val_loss: 0.7956 - val_mean_squared_error: 0.7956\n",
      "\n",
      "Epoch 00042: loss improved from 0.47500 to 0.45320, saving model to base_model\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4778 - mean_squared_error: 0.4778 - val_loss: 1.0321 - val_mean_squared_error: 1.0321\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.45320\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4856 - mean_squared_error: 0.4856 - val_loss: 0.8898 - val_mean_squared_error: 0.8898\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.45320\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4673 - mean_squared_error: 0.4673 - val_loss: 0.9390 - val_mean_squared_error: 0.9390\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.45320\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4410 - mean_squared_error: 0.4410 - val_loss: 0.9493 - val_mean_squared_error: 0.9493\n",
      "\n",
      "Epoch 00046: loss improved from 0.45320 to 0.44104, saving model to base_model\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4318 - mean_squared_error: 0.4318 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
      "\n",
      "Epoch 00047: loss improved from 0.44104 to 0.43179, saving model to base_model\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4584 - mean_squared_error: 0.4584 - val_loss: 0.8633 - val_mean_squared_error: 0.8633\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.43179\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5303 - mean_squared_error: 0.5303 - val_loss: 0.8279 - val_mean_squared_error: 0.8279\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.43179\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3910 - mean_squared_error: 0.3910 - val_loss: 0.9286 - val_mean_squared_error: 0.9286\n",
      "\n",
      "Epoch 00050: loss improved from 0.43179 to 0.39099, saving model to base_model\n"
     ]
    }
   ],
   "source": [
    "test_size = len(x_train)\n",
    "hist = lstm.fit(x_train, y_train, epochs = 50, callbacks = callback_list, validation_split = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_weights('base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 2.6 Predicted: [[2.8350923]]\n"
     ]
    }
   ],
   "source": [
    "num = 379\n",
    "p = x_train[num]\n",
    "p = p.reshape(1, 6, output_size)\n",
    "print('Actual: {} Predicted: {}' .format(y_train[num], lstm.predict(x_train[num:num + 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lstm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.639977546818\n",
      "RMSE: 0.799985966638\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, preds)\n",
    "print('MSE: {}' .format(mse))\n",
    "print('RMSE: {}' .format(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_mn = MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "for layer in unified_mn.layers[:7]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_model = Sequential()\n",
    "unified_model.add(TimeDistributed(unified_mn, input_shape=(6, 224, 224, 3)))\n",
    "unified_model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))))\n",
    "unified_model.add(TimeDistributed(MaxPooling2D()))\n",
    "unified_model.add(TimeDistributed(Flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_47 (TimeDis (None, 6, 7, 7, 1024)     3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 6, 3, 3, 1024)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 6, 1, 1, 1024)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 6, 1024)           0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 6, 128)            590336    \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,950,913\n",
      "Trainable params: 3,927,745\n",
      "Non-trainable params: 23,168\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unified_model.add(LSTM(128, return_sequences = True))\n",
    "unified_model.add(LSTM(128, dropout = .2))\n",
    "unified_model.add(Dense(1))\n",
    "unified_model.compile(loss='mse', optimizer='adam', metrics = [metrics.mean_squared_error])\n",
    "unified_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 6, 224, 224, 3)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tensor_stack).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 224, 224, 3)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_stack[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor_stack[0].reshape(1,6,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 26s 26s/step - loss: 209.0516 - mean_squared_error: 209.0516\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 2s 2s/step - loss: 162.6521 - mean_squared_error: 162.6521\n"
     ]
    }
   ],
   "source": [
    "t_hist = unified_model.fit(t, targets[:1], epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
